{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cataloguing the data\n",
    "\n",
    "## Example 1: Forced photometry and producing photometric catalogues\n",
    "\n",
    "The primary use for the galfind `Data` object is the creation of photometric catalogues for public and personal use. Once produced, these catalogues can be loaded into the `Catalogue` class to derive specific properties, which we cover in the [next section](../catalogue/catalogue.rst). In this first galfind release, we implement the ability to produce these using SExtractor only, although we aim to include other codes to perform forced photometry in the near future. \n",
    "\n",
    "The `Data.perform_forced_phot()` is used to:\n",
    "1. Perform forced photometry using a specific selection band, including the possibility of using stacked data\n",
    "2. Produce a photometric catalogue with aperture (and Kron) fluxes in a range of chosen aperture sizes, and other associated (currently just SExtractor) derived properties\n",
    "3. Create a README for the catalogue which is updated at runtime to describe what is included\n",
    "\n",
    "To start with, after loading the same JOF `Data` object we have seen in previous examples, we will make a catalogue using `forced_phot_band=F444W`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from astropy.table import Table\n",
    "from copy import deepcopy\n",
    "\n",
    "from galfind import Stacked_Band_Data, Data\n",
    "from galfind.Data import morgan_version_to_dir\n",
    "\n",
    "survey = \"JOF\"\n",
    "version = \"v11\"\n",
    "instrument_names = [\"NIRCam\"]\n",
    "JOF_data = Data.from_survey_version(\n",
    "    survey, \n",
    "    version, \n",
    "    instrument_names = instrument_names, \n",
    "    version_to_dir_dict = morgan_version_to_dir,\n",
    ")\n",
    "JOF_data.perform_forced_phot(forced_phot_band = \"F444W\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will search the GALFIND_WORK directory for the individual forced photometry catalogues for each band and the resulting catalogue/README to ensure they exist and have been created correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for hpotometric catalogue\n",
    "if Path(JOF_data.phot_cat_path).is_file():\n",
    "    print(\"Photometric catalogue exists at the expected path.\")\n",
    "    # open the photometric catalogue\n",
    "    phot_cat = Table.read(JOF_data.phot_cat_path)\n",
    "    print(phot_cat)\n",
    "else:\n",
    "    print(\"Photometric catalogue does not exist at the expected path.\")\n",
    "\n",
    "# search for README\n",
    "readme_path = JOF_data.phot_cat_path.replace(\".fits\", \"_README.txt\")\n",
    "if Path(readme_path).is_file():\n",
    "    print(\"README exists at the expected path.\")\n",
    "    # print the README\n",
    "    with open(readme_path, \"r\") as f:\n",
    "        print(f.read())\n",
    "        f.close()\n",
    "else:\n",
    "    print(\"README does not exist at the expected path.\")\n",
    "\n",
    "# search for forced photometry catalogues for each included filter\n",
    "for band_data in JOF_data:\n",
    "    if Path(band_data.forced_phot_cat_path).is_file():\n",
    "        print(f\"Forced photometry catalogue for {band_data.filter_name} exists at the expected path.\")\n",
    "    else:\n",
    "        print(f\"Forced photometry catalogue for {band_data.filter_name} does not exist at the expected path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at how this changes the `Data` print statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(JOF_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For safety reasons, once the (path to the) photometric catalogue has been loaded into the Data object, it is not possible to re-run it. This is so that, for example, you don't get confused between the products stemming from the previous catalogue and your newly loaded in one. To be clear, the `overwrite` parameter that we have been using simply states whether the pre-existing paths should be overwritten with the new data and NOT whether the data stored in the object should be updated. Preventing stored paths from being overwritten in a particular object, however, does not entirely prevent you from changing the outputs of any methods run from those stored paths as the information is not cached in a single object, rather extracted from the data products when required. Let's try re-producing this SExtractor forced photometric catalogue but instead using the F356W filter for selection in the same object to see what error message we get out of galfind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOF_data.perform_forced_phot(forced_phot_band = \"F356W\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a second object now (and a deepcopied third pre-forced photometry for later in the notebook) and have a go at performing the forced photometry once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOF_data_2 = Data.from_survey_version(\n",
    "    survey, \n",
    "    version, \n",
    "    instrument_names = instrument_names, \n",
    "    version_to_dir_dict = morgan_version_to_dir,\n",
    ")\n",
    "JOF_data_3 = deepcopy(JOF_data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we will attempt to produce a photometric catalogue selecting from a stack of F277W, F356W, and F444W as in the EPOCHS series as well as a host of other high-redshift studies. To do this, we will need to create a `Stacked_Band_Data` object, as seen before in example 3 of the [Data class introduction notebook](data_intro.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_filters = [\"F277W\", \"F356W\", \"F444W\"]\n",
    "stacked_NIRCam_LW = Stacked_Band_Data.from_band_data_arr(JOF_data_2[select_filters])\n",
    "print(stacked_NIRCam_LW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Running the Data pipeline\n",
    "\n",
    "There is one last class method for the Data object that we havn't quite covered yet, `Data.pipeline()` which again just takes `survey` and `version` inputs. This class method is what is used in the EPOCHS pipeline and essentially just chains the cataloguing steps in the previous notebooks together elegantly, skipping those that have already been executed in the past. For further details, please read the previous notebooks in this section if you have not already done so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from galfind import Data\n",
    "\n",
    "survey = \"JOF\"\n",
    "version = \"v11\"\n",
    "\n",
    "# load the data object (short version)\n",
    "data_short = Data.pipeline(survey, version)\n",
    "\n",
    "# load the data object (long version)\n",
    "data_long = Data.from_survey_version(survey, version)\n",
    "data_long.PSF_homogenize(\"F444W\")\n",
    "data_long.segment(\"sextractor\")\n",
    "data_long.perform_forced_phot([\"F277W\", \"F356W\", \"F444W\"])\n",
    "data_long.mask()\n",
    "data_long.run_depths()\n",
    "\n",
    "# ensure the two data objects are the same\n",
    "assert data_short == data_long\n",
    "\n",
    "# show the data object attributes\n",
    "print(data_short)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
